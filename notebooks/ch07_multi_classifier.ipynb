{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "ch07_multi_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VITk-OcB8wF"
      },
      "source": [
        "# PDF印刷用\n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('png', 'pdf')\n",
        "\n",
        "try:\n",
        "    from google.colab import files\n",
        "except:\n",
        "    pass\n",
        "\n",
        "pdf_ind = 1\n",
        "pdf_base = 'pdf-07-'\n",
        "\n",
        "def create_pdf(plt):\n",
        "    global pdf_ind, pdf_base\n",
        "    fn = f'{pdf_base}{pdf_ind:02d}.pdf'\n",
        "    print(fn)\n",
        "    plt.savefig(fn)\n",
        "    try:\n",
        "        files.download(fn)\n",
        "    except:\n",
        "        pass\n",
        "    pdf_ind = pdf_ind + 1\n",
        "\n",
        "def graph_pdf(g):\n",
        "    global pdf_ind, pdf_base\n",
        "    fnbase = f'{pdf_base}{pdf_ind:02d}'\n",
        "    fn = f'{pdf_base}{pdf_ind:02d}.pdf'\n",
        "    print(fnbase)\n",
        "    g.render(fnbase, view=False)\n",
        "    try:\n",
        "        files.download(fn)\n",
        "    except:\n",
        "        pass\n",
        "    pdf_ind = pdf_ind + 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch7QhC-aB8wI"
      },
      "source": [
        "# 7章　多値分類"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovFKq7VJB8wJ"
      },
      "source": [
        "# 必要ライブラリの導入\n",
        "\n",
        "!pip install japanize_matplotlib | tail -n 1\n",
        "!pip install torchviz | tail -n 1\n",
        "!pip install torchinfo | tail -n 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuXbWMV0B8wK"
      },
      "source": [
        "# 必要ライブラリのインポート\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "from IPython.display import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HGKvQdjB8wK"
      },
      "source": [
        "# torch関連ライブラリのインポート\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchinfo import summary\n",
        "from torchviz import make_dot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xktdy7SfB8wK"
      },
      "source": [
        "# デフォルトフォントサイズ変更\n",
        "plt.rcParams['font.size'] = 14\n",
        "\n",
        "# デフォルトグラフサイズ変更\n",
        "plt.rcParams['figure.figsize'] = (6,6)\n",
        "\n",
        "# デフォルトで方眼表示ON\n",
        "plt.rcParams['axes.grid'] = True\n",
        "\n",
        "# numpyの表示桁数設定\n",
        "np.set_printoptions(suppress=True, precision=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmcpTYteB8wL"
      },
      "source": [
        "## 7.8 データ準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXtUTacMB8wM"
      },
      "source": [
        "### データ読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "DL7lXe4hB8wM"
      },
      "source": [
        "# 学習用データ準備\n",
        "\n",
        "# ライブラリのインポート\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# データ読み込み\n",
        "iris = load_iris()\n",
        "\n",
        "# 入力データと正解データ取得\n",
        "x_org, y_org = iris.data, iris.target\n",
        "\n",
        "# 結果確認\n",
        "print('元データ', x_org.shape, y_org.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dOTzVWYB8wM"
      },
      "source": [
        "### データ絞り込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgWVyVe_B8wM"
      },
      "source": [
        "# データ絞り込み\n",
        "\n",
        "# 入力データに関しては、sepal length(0)とpetal length(2)のみ抽出\n",
        "x_select = x_org[:,[0,2]]\n",
        "\n",
        "# 結果確認\n",
        "print('元データ', x_select.shape, y_org.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDu-VbBQB8wM"
      },
      "source": [
        "### 訓練データ・検証データの分割"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHtoGNaiB8wN"
      },
      "source": [
        "# 訓練データ、検証データに分割 (シャフルも同時に実施)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x_select, y_org, train_size=75, test_size=75, \n",
        "    random_state=123)\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hn8In74JB8wN"
      },
      "source": [
        "### 訓練データの散布図表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5duf5mMpB8wN"
      },
      "source": [
        "# データを正解値ごとに分割\n",
        "\n",
        "x_t0 = x_train[y_train == 0]\n",
        "x_t1 = x_train[y_train == 1]\n",
        "x_t2 = x_train[y_train == 2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "tYaWqq7IB8wN"
      },
      "source": [
        "# 散布図の表示\n",
        "\n",
        "plt.scatter(x_t0[:,0], x_t0[:,1], marker='x', c='k', s=50, label='0 (setosa)')\n",
        "plt.scatter(x_t1[:,0], x_t1[:,1], marker='o', c='b', s=50, label='1 (versicolour)')\n",
        "plt.scatter(x_t2[:,0], x_t2[:,1], marker='+', c='k', s=50, label='2 (virginica)')\n",
        "plt.xlabel('sepal_length')\n",
        "plt.ylabel('petal_length')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6jQZHH6B8wN"
      },
      "source": [
        "## 7.9 モデル定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUx0cencB8wO"
      },
      "source": [
        "# 学習用パラメータ設定\n",
        "\n",
        "# 入力次元数\n",
        "n_input = x_train.shape[1]\n",
        "\n",
        "# 出力次元数\n",
        "# 分類先クラス数　今回は3になる\n",
        "n_output = len(list(set(y_train)))\n",
        "\n",
        "# 結果確認\n",
        "print(f'n_input: {n_input}  n_output: {n_output}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5UmhWa2B8wO"
      },
      "source": [
        "# モデルの定義\n",
        "# 2入力3出力のロジスティック回帰モデル\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, n_input, n_output):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(n_input, n_output)\n",
        "                \n",
        "        # 初期値を全部1にする\n",
        "        # 「ディープラーニングの数学」と条件を合わせる目的        \n",
        "        self.l1.weight.data.fill_(1.0)\n",
        "        self.l1.bias.data.fill_(1.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.l1(x)\n",
        "        return x1\n",
        "    \n",
        "# インスタンスの生成\n",
        "net = Net(n_input, n_output)        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVNOGdyTB8wO"
      },
      "source": [
        "### モデル確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHvoNQRRB8wO"
      },
      "source": [
        "# モデル内のパラメータの確認\n",
        "# l1.weightが行列にl1.biasがベクトルになっている\n",
        "\n",
        "for parameter in net.named_parameters():\n",
        "    print(parameter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiUZvDi_B8wP"
      },
      "source": [
        "# モデルの概要表示\n",
        "\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNobe3FvB8wP"
      },
      "source": [
        "# モデルのサマリー表示\n",
        "\n",
        "summary(net, (2,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sBrtt-ZB8wP"
      },
      "source": [
        "### 最適化アルゴリズムと損失関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmEw7VFWB8wP"
      },
      "source": [
        "# 損失関数： 交差エントロピー関数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 学習率\n",
        "lr = 0.01\n",
        "\n",
        "# 最適化関数: 勾配降下法\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "508vYI0zB8wP"
      },
      "source": [
        "## 7.10 勾配降下法"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKKMMHq2B8wP"
      },
      "source": [
        "### データのTensor化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOg9_jE9B8wP"
      },
      "source": [
        "# 入力変数x_trainと正解値 y_trainのテンソル変数化\n",
        "\n",
        "inputs = torch.tensor(x_train).float()\n",
        "labels = torch.tensor(y_train).long()\n",
        "\n",
        "# 検証用変数のテンソル変数化\n",
        "\n",
        "inputs_test = torch.tensor(x_test).float()\n",
        "labels_test = torch.tensor(y_test).long()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo-FPvbQB8wQ"
      },
      "source": [
        "### 計算グラフの視覚化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv663B7hB8wQ"
      },
      "source": [
        "# 予測計算\n",
        "outputs = net(inputs)\n",
        "\n",
        "#  損失計算\n",
        "loss = criterion(outputs, labels)\n",
        "\n",
        "# 損失の計算グラフ化\n",
        "g = make_dot(loss, params=dict(net.named_parameters()))\n",
        "display(g)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cbHG6zdB8wQ"
      },
      "source": [
        "### 予測ラベル値の取得方法"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "2fQ-IYOtB8wR"
      },
      "source": [
        "# torch.max関数呼び出し\n",
        "# 2つめの引数は軸を意味している。1だと行ごとの集計。\n",
        "print(torch.max(outputs, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYW8R14iB8wR"
      },
      "source": [
        "# ラベル値の配列を取得\n",
        "torch.max(outputs, 1)[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUq1owdoB8wR"
      },
      "source": [
        "### 繰り返し計算"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6vnUjx8B8wR"
      },
      "source": [
        "# 学習率\n",
        "lr = 0.01\n",
        "\n",
        "# 初期化\n",
        "net = Net(n_input, n_output)\n",
        "\n",
        "# 損失関数： 交差エントロピー関数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化関数: 勾配降下法\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "# 繰り返し回数\n",
        "num_epochs = 10000\n",
        "\n",
        "# 評価結果記録用\n",
        "history = np.zeros((0,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dky9vOVqB8wR"
      },
      "source": [
        "# 繰り返し計算メインループ\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # 学習フェーズ\n",
        "    \n",
        "    #勾配の初期化\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 予測計算\n",
        "    outputs = net(inputs)\n",
        "\n",
        "    # 損失計算\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # 勾配計算\n",
        "    loss.backward()\n",
        "    \n",
        "    # 重み修正\n",
        "    optimizer.step()\n",
        "\n",
        "    # 予測ラベル算出\n",
        "    predicted = torch.max(outputs, 1)[1]\n",
        "\n",
        "    # 損失と精度の計算\n",
        "    train_loss = loss.item()\n",
        "    train_acc = (predicted == labels).sum()  / len(labels)\n",
        "\n",
        "    #予測フェーズ\n",
        "\n",
        "    # 予測計算\n",
        "    outputs_test = net(inputs_test)\n",
        "\n",
        "    # 損失計算\n",
        "    loss_test = criterion(outputs_test, labels_test)\n",
        "\n",
        "    # 予測ラベル算出\n",
        "    predicted_test = torch.max(outputs_test, 1)[1]\n",
        "\n",
        "    # 損失と精度の計算\n",
        "    val_loss =  loss_test.item()\n",
        "    val_acc =  (predicted_test == labels_test).sum() / len(labels_test)\n",
        "    \n",
        "    if ((epoch) % 10 == 0):\n",
        "        print (f'Epoch [{epoch}/{num_epochs}], loss: {train_loss:.5f} acc: {train_acc:.5f} val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
        "        item = np.array([epoch, train_loss, train_acc, val_loss, val_acc])\n",
        "        history = np.vstack((history, item))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOztcpv3B8wS"
      },
      "source": [
        "## 7.11 結果確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5EZQ946B8wS"
      },
      "source": [
        "#損失と精度の確認\n",
        "\n",
        "print(f'初期状態: 損失: {history[0,3]:.5f} 精度: {history[0,4]:.5f}' )\n",
        "print(f'最終状態: 損失: {history[-1,3]:.5f} 精度: {history[-1,4]:.5f}' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbibwG3bB8wS"
      },
      "source": [
        "# 学習曲線の表示 (損失)\n",
        "\n",
        "plt.plot(history[:,0], history[:,1], 'b', label='訓練')\n",
        "plt.plot(history[:,0], history[:,3], 'k', label='検証')\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('損失')\n",
        "plt.title('学習曲線(損失)')\n",
        "plt.legend()\n",
        "create_pdf(plt)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJnWmovUB8wS"
      },
      "source": [
        "# 学習曲線の表示 (精度)\n",
        "\n",
        "plt.plot(history[:,0], history[:,2], 'b', label='訓練')\n",
        "plt.plot(history[:,0], history[:,4], 'k', label='検証')\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('精度')\n",
        "plt.title('学習曲線(精度)')\n",
        "plt.legend()\n",
        "create_pdf(plt)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JG3V10NNB8wT"
      },
      "source": [
        "### モデルへの入力と出力の確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWjT02ChB8wT"
      },
      "source": [
        "# 正解データの0番目、2番目、3番目\n",
        "\n",
        "print(labels[[0,2,3]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2j8v5mnCB8wT"
      },
      "source": [
        "# 該当する入力値を抽出\n",
        "\n",
        "i3 = inputs[[0,2,3],:]\n",
        "print(i3.data.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9skIo4OwB8wT"
      },
      "source": [
        "# 出力値にsoftmax関数をかけた結果を取得\n",
        "\n",
        "softmax = torch.nn.Softmax(dim=1)\n",
        "o3 = net(i3)\n",
        "k3 = softmax(o3)\n",
        "print(o3.data.numpy())\n",
        "print(k3.data.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPlEVs83B8wT"
      },
      "source": [
        "### 最終的な重み行列とバイアスの値"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA6qeTWHB8wU"
      },
      "source": [
        "# 重み行列\n",
        "print(net.l1.weight.data)\n",
        "\n",
        "# バイアス\n",
        "print(net.l1.bias.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m016TNL9B8wU"
      },
      "source": [
        "## 7.12 入力変数の4次元化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI61G1-GB8wU"
      },
      "source": [
        "# 学習データ、検証データに分割 (シャフルも同時に実施)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x_org, y_org, train_size=75, test_size=75, \n",
        "    random_state=123)\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "# 入力次元数\n",
        "n_input = x_train.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziivFupuB8wU"
      },
      "source": [
        "print('入力データ(x)')\n",
        "print(x_train[:5,:])\n",
        "print(f'入力次元数: {n_input}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFZ-B_yyB8wU"
      },
      "source": [
        "# 入力変数x_trainと正解値 y_trainのTesor化\n",
        "inputs = torch.tensor(x_train).float()\n",
        "labels = torch.tensor(y_train).long()\n",
        "\n",
        "# 検証用変数のTensor化\n",
        "inputs_test = torch.tensor(x_test).float()\n",
        "labels_test = torch.tensor(y_test).long()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DORSG_Q2B8wU"
      },
      "source": [
        "# 学習率\n",
        "lr = 0.01\n",
        "\n",
        "# 初期化\n",
        "net = Net(n_input, n_output)\n",
        "\n",
        "# 損失関数： 交差エントロピー関数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化アルゴリズム: 勾配降下法\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "# 繰り返し回数\n",
        "num_epochs = 10000\n",
        "\n",
        "# 評価結果記録用\n",
        "history = np.zeros((0,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Y4gM9OQgB8wV"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # 学習フェーズ\n",
        "    \n",
        "    #勾配の初期化\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 予測計算\n",
        "    outputs = net(inputs)\n",
        "\n",
        "    # 損失計算\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # 勾配計算\n",
        "    loss.backward()\n",
        "    \n",
        "    # 重み修正\n",
        "    optimizer.step()\n",
        "\n",
        "    #予測値算出\n",
        "    predicted = torch.max(outputs, 1)[1]\n",
        "\n",
        "    # 損失と精度の計算\n",
        "    train_loss = loss.item()\n",
        "    train_acc = (predicted == labels).sum()  / len(labels)\n",
        "\n",
        "    #予測フェーズ\n",
        "\n",
        "    # 予測計算\n",
        "    outputs_test = net(inputs_test)\n",
        "\n",
        "    # 損失計算\n",
        "    loss_test = criterion(outputs_test, labels_test)\n",
        "\n",
        "    # 予測ラベル算出\n",
        "    predicted_test = torch.max(outputs_test, 1)[1]\n",
        "\n",
        "    # 損失と精度の計算\n",
        "    val_loss =  loss_test.item()\n",
        "    val_acc =  (predicted_test == labels_test).sum() / len(labels_test)\n",
        "    \n",
        "    if ( epoch % 10 == 0):\n",
        "        print (f'Epoch [{epoch}/{num_epochs}], loss: {train_loss:.5f} acc: {train_acc:.5f} val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
        "        item = np.array([epoch , train_loss, train_acc, val_loss, val_acc])\n",
        "        history = np.vstack((history, item))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGnDSJReB8wV"
      },
      "source": [
        "#損失と精度の確認\n",
        "\n",
        "print(f'初期状態: 損失: {history[0,3]:.5f} 精度: {history[0,4]:.5f}' )\n",
        "print(f'最終状態: 損失: {history[-1,3]:.5f} 精度: {history[-1,4]:.5f}' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4NJkJDJB8wV"
      },
      "source": [
        "# 学習曲線の表示 (損失)\n",
        "\n",
        "plt.plot(history[:,0], history[:,1], 'b', label='訓練')\n",
        "plt.plot(history[:,0], history[:,3], 'k', label='検証')\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('損失')\n",
        "plt.title('学習曲線(損失)')\n",
        "plt.legend()\n",
        "create_pdf(plt)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZPEkfLJB8wW"
      },
      "source": [
        "# 学習曲線の表示 (精度)\n",
        "\n",
        "plt.plot(history[:,0], history[:,2], 'b', label='訓練')\n",
        "plt.plot(history[:,0], history[:,4], 'k', label='検証')\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('精度')\n",
        "plt.title('学習曲線(精度)')\n",
        "plt.legend()\n",
        "create_pdf(plt)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwXP0yeKB8wK"
      },
      "source": [
        "## コラム NLLLoss損失関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg7-oAJ4B8wL"
      },
      "source": [
        "# 入力変数の準備\n",
        "\n",
        "# 擬似的な出力データ\n",
        "outputs_np = np.array(range(1, 13)).reshape((4,3))\n",
        "# 擬似的な正解データ\n",
        "labels_np = np.array([0, 1, 2, 0])\n",
        "\n",
        "# Tensor化\n",
        "outputs_dummy = torch.tensor(outputs_np).float()\n",
        "labels_dummy = torch.tensor(labels_np).long()\n",
        "\n",
        "# 結果確認\n",
        "print(outputs_dummy.data)\n",
        "print(labels_dummy.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf68l_reB8wL"
      },
      "source": [
        "# NLLLoss関数の呼び出し\n",
        "\n",
        "nllloss = nn.NLLLoss()\n",
        "loss = nllloss(outputs_dummy, labels_dummy)\n",
        "print(loss.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyX9w-MPB8wW"
      },
      "source": [
        "## コラム 多値分類モデルの他の実装パターン"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYdZPF06B8wW"
      },
      "source": [
        "### パターン2 モデルクラス側にLogS1oftmax関数を含める"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cgth7H98B8wW"
      },
      "source": [
        "# モデルの定義\n",
        "# 2入力3出力のロジスティック回帰モデル\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, n_input, n_output):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(n_input, n_output)\n",
        "        # softmax関数の定義\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "                \n",
        "        # 初期値を全部1にする\n",
        "        # 「ディープラーニングの数学」と条件を合わせる目的        \n",
        "        self.l1.weight.data.fill_(1.0)\n",
        "        self.l1.bias.data.fill_(1.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.l1(x)\n",
        "        x2 = self.logsoftmax(x1)\n",
        "        return x2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuL4yILWGMzZ"
      },
      "source": [
        "# 学習率\n",
        "lr = 0.01\n",
        "\n",
        "# 初期化\n",
        "net = Net(n_input, n_output)\n",
        "\n",
        "# 損失関数： NLLLoss関数\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# 最適化関数: 勾配降下法\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uyUhRWLFjt5"
      },
      "source": [
        "# 予測計算\n",
        "outputs = net(inputs)\n",
        "\n",
        "#  損失計算\n",
        "loss = criterion(outputs, labels)\n",
        "\n",
        "# 損失関数の計算グラフ化\n",
        "g = make_dot(loss, params=dict(net.named_parameters()))\n",
        "display(g)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AgjZ2WFFrpy"
      },
      "source": [
        "graph_pdf(g)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU9rqn5NB8wW"
      },
      "source": [
        "# 学習率\n",
        "lr = 0.01\n",
        "\n",
        "# 初期化\n",
        "net = Net(n_input, n_output)\n",
        "\n",
        "# 損失関数： NLLLoss関数\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# 最適化関数: 勾配降下法\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "# 繰り返し回数\n",
        "num_epochs = 10000\n",
        "\n",
        "# 評価結果記録用\n",
        "history = np.zeros((0,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsTrCuQ_B8wW"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # 学習フェーズ\n",
        "    \n",
        "    #勾配の初期化\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 予測計算\n",
        "    outputs = net(inputs)\n",
        "\n",
        "    # 損失計算\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # 勾配計算\n",
        "    loss.backward()\n",
        "    \n",
        "    # 重み修正\n",
        "    optimizer.step()\n",
        "\n",
        "    #予測ラベル算出\n",
        "    predicted = torch.max(outputs, 1)[1]\n",
        "\n",
        "    # 損失と精度の計算\n",
        "    train_loss = loss.item()\n",
        "    train_acc = (predicted == labels).sum()  / len(labels)\n",
        "\n",
        "    #予測フェーズ\n",
        "\n",
        "    # 予測計算\n",
        "    outputs_test = net(inputs_test)\n",
        "\n",
        "    # 損失計算\n",
        "    loss_test = criterion(outputs_test, labels_test)\n",
        "\n",
        "    #予測ラベル算出\n",
        "    predicted_test = torch.max(outputs_test, 1)[1]\n",
        "\n",
        "    # 損失と精度の計算\n",
        "    val_loss =  loss_test.item()\n",
        "    val_acc =  (predicted_test == labels_test).sum() / len(labels_test)\n",
        "    \n",
        "    if ( epoch % 10 == 0):\n",
        "        print (f'Epoch [{epoch}/{num_epochs}], loss: {train_loss:.5f} acc: {train_acc:.5f} val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
        "        item = np.array([epoch , train_loss, train_acc, val_loss, val_acc])\n",
        "        history = np.vstack((history, item))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hOWu3ETB8wX"
      },
      "source": [
        "#損失と精度の確認\n",
        "\n",
        "print(f'初期状態: 損失: {history[0,3]:.5f} 精度: {history[0,4]:.5f}' )\n",
        "print(f'最終状態: 損失: {history[-1,3]:.5f} 精度: {history[-1,4]:.5f}' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA3h1wFsB8wX"
      },
      "source": [
        "# パターン1モデルの出力結果\n",
        "w = outputs[:5,:].data\n",
        "print(w.numpy())\n",
        "\n",
        "# 確率値を得たい場合\n",
        "print(torch.exp(w).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiDG6LXeB8wX"
      },
      "source": [
        "### パターン3 モデルクラス側は素のsoftmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK5H4lElB8wX"
      },
      "source": [
        "# モデルの定義\n",
        "# 2入力3出力のロジスティック回帰モデル\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, n_input, n_output):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(n_input, n_output)\n",
        "        # softmax関数の定義\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "                \n",
        "        # 初期値を全部1にする\n",
        "        # 「ディープラーニングの数学」と条件を合わせる目的        \n",
        "        self.l1.weight.data.fill_(1.0)\n",
        "        self.l1.bias.data.fill_(1.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.l1(x)\n",
        "        x2 = self.softmax(x1)\n",
        "        return x2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw5Z4sbcB8wX"
      },
      "source": [
        "# 学習率\n",
        "lr = 0.01\n",
        "\n",
        "# 初期化\n",
        "net = Net(n_input, n_output)\n",
        "\n",
        "# 損失関数： NLLLoss関数\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# 最適化関数: 勾配降下法\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "# 繰り返し回数\n",
        "num_epochs = 10000\n",
        "\n",
        "# 評価結果記録用\n",
        "history = np.zeros((0,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qAnByPtB8wY"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # 学習フェーズ\n",
        "    \n",
        "    #勾配の初期化\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 予測計算\n",
        "    outputs = net(inputs)\n",
        "    \n",
        "    # ここで対数関数にかける\n",
        "    outputs2 = torch.log(outputs)\n",
        "\n",
        "    # 損失計算\n",
        "    loss = criterion(outputs2, labels)\n",
        "\n",
        "    # 勾配計算\n",
        "    loss.backward()\n",
        "    \n",
        "    # 重み修正\n",
        "    optimizer.step()\n",
        "\n",
        "    #予測ラベル算出\n",
        "    predicted = torch.max(outputs, 1)[1]\n",
        "\n",
        "    # 損失と精度の計算\n",
        "    train_loss = loss.item()\n",
        "    train_acc = (predicted == labels).sum()  / len(labels)\n",
        "\n",
        "    #予測フェーズ\n",
        "\n",
        "    # 予測計算\n",
        "    outputs_test = net(inputs_test)\n",
        "        \n",
        "    # ここで対数関数にかける\n",
        "    outputs2_test = torch.log(outputs_test)\n",
        "\n",
        "    # 損失計算\n",
        "    loss_test = criterion(outputs2_test, labels_test)\n",
        "\n",
        "    #予測ラベル算出\n",
        "    predicted_test = torch.max(outputs_test, 1)[1]\n",
        "\n",
        "    # 対する損失と精度の計算\n",
        "    val_loss =  loss_test.item()\n",
        "    val_acc =  (predicted_test == labels_test).sum() / len(labels_test)\n",
        "    \n",
        "    if ( epoch % 10 == 0):\n",
        "        print (f'Epoch [{epoch}/{num_epochs}], loss: {train_loss:.5f} acc: {train_acc:.5f} val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
        "        item = np.array([epoch , train_loss, train_acc, val_loss, val_acc])\n",
        "        history = np.vstack((history, item))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvqi0lCOB8wY"
      },
      "source": [
        "#損失と精度の確認\n",
        "\n",
        "print(f'初期状態: 損失: {history[0,3]:.5f} 精度: {history[0,4]:.5f}' )\n",
        "print(f'最終状態: 損失: {history[-1,3]:.5f} 精度: {history[-1,4]:.5f}' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_faCAG1B8wY"
      },
      "source": [
        "# パターン2のモデル出力値\n",
        "w = outputs[:5,:].data.numpy()\n",
        "print(w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ2AicieB8wY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}